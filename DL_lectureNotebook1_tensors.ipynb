{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmf0920/Feiii_code/blob/main/DL_lectureNotebook1_tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDpQ-i6p0Tey"
      },
      "source": [
        "#Getting started with tensors in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRRuF0X8xnmf"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWncMBGN1rA6"
      },
      "source": [
        "# Data representation in neural networks\n",
        "\n",
        "Modern machine-learning systems use *tensors* as their basic data structures. These are fundamentally containers for data. You will already have used matrices, which are examples of two-dimensional tensors. The tensor's *rank* is its number of axes (like dimensions for a matrix)\n",
        "\n",
        "# Tensors\n",
        "\n",
        "*  Scalars: Tensors which contain only one number. 0-dimensional tensors\n",
        "*  Vectors (1D tensors). An array of numbers is a vector or 1D tensor, and has one axis.\n",
        "*  Matrices are 2D tensors. The two axes are referred to as *rows* and *columns*\n",
        "*  3D tensors and higher. Putting a 2D matrix in a new array gives you a 3D tensor (and so on to higher dimensions..). You will end up spending a lot of time making sure your tensors are the right shape, when debugging your deep networks... :-)\n",
        "\n",
        "* Manipulating tensors in Numpy\n",
        "* data batches\n",
        "* Examples of training data used, in each case with $N=$ `samples` examples in the set:\n",
        "   * Vector data - 2D `(samples, features)`\n",
        "   * Time-series/sequence data - 3D tensors shaped `(samples, timesteps, features)`)\n",
        "   \n",
        "   ![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRrnL1abPz6Nkugh29zNvaq-L_KqAvJAIBJQdr_dpi4Khpnrn_sww)\n",
        "   * Image data -- 4D tensors shaped `(samples, height, width, channels)`\n",
        "   \n",
        "   ![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRbVhpi2ZiSb7fl0Q8YMXBhMQ7Ny-rwHG82TEpjgIm8yKCfiV0r)\n",
        "   * Video data - 5D tensors shaped `(samples, frames, height, width, channels)`. Think about the memory requirements of these tensors. How much memory would you need for a 60 second video at 256x256 sampled 30 times a second?\n",
        "---\n",
        "# Tensor operations\n",
        "\n",
        "* Element-wise operations - e.g. the activation function `relu()` when implemented as `torch.max(z,0.0)` is applied independently to each entry of the tensor considered (rather than using a `for` loop to run through each entry). Usually much more efficient than implementing loops. In a number of cases these element-wise operations are different from the typical operations on matrices. So element-wise multiplication corresponds to the Hadamard product $z = x \\odot y$ (sometimes written $x \\circ y$) where each element is multiplied together to get a new element rather than the typical matrix multiplication.\n",
        "* Broadcasting - when the shapes of tensors differs and there is no ambiguity, and the results are legal, the smaller tensor can be *broadcasted* to match the shape of the larger tensor.\n",
        "     * this has two steps:\n",
        "     1. axes are added to the smaller tensor to match the `ndim` of the larger (from the left-hand side)\n",
        "     2. the smaller tensor is repeated alongside any axes (assuming they are a multiple of the larger axes size) to match the full shape of the larger tensor.\n",
        "     E.g.\n",
        "     \n",
        "     `x = torch.rand(64,3,32,10)`\n",
        "     \n",
        "    `y = torch.rand(3, 32, 1)`\n",
        "    \n",
        "    `z = torch.max(x,y)` - z has shape (64,3,32,10) like `x`\n",
        "    \n",
        "* Tensor dot - aka *tensor product* . In torch use `z=torch.dot(x,y)`, in mathematical notation $z=x \\cdot y$. Note this is different from the elementwise multiplication `z=x*y`. The dot product of two vectors (which have to be the same size) is a scalar. The dot product of a matrix $x$ and a vector $y$ is a vector where the cofficients are the dot products between $y$ and the rows of $x$.\n",
        "* Tensor reshaping\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8NSa2l1aCGh",
        "outputId": "64bdffc2-a4a2-4945-c88a-537c2efe0784",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x=torch.ones(64, 3, 32, 10)#生成一个形状为(64,3,32,10)的张量，所有的元素都初始化为1\n",
        "y=torch.ones(3, 32, 1)#生成一个形状为(3,32,1)的张量，所有的元素都为1\n",
        "z = torch.max(x, y)#计算求解x和y的逐元素最大值，赋给z\n",
        "#因为y的维度小，所以需要先将y进行广播，将y扩展成与x相同的形状，所以要从左边增加一个轴（补充一个1），将1广播成64(与x相同)\n",
        "#中间两个轴与x值相同，所以重复，最后一个扩张到x的大小(10)\n",
        "#然后将x和广播后的y在每个位置上进行比较取最大值，因为都是1，所以最后z的每个元素也都是1\n",
        "#z的形状与x相同\n",
        "\n",
        "#分别打印出z和z的形状\n",
        "print(z)\n",
        "print(z.size())\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
            "\n",
            "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]]]])\n",
            "torch.Size([64, 3, 32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us0Ekrytxnmp"
      },
      "source": [
        "Note that when an uninitialized matrix is created, whatever values were in the allocated memory at the time will appear as the initial values.\n",
        "\n",
        "请注意，当创建一个未初始化的矩阵时，分配的内存中的任何值都会作为初始值出现。（意思是如果创建一个新的张量但没有给它赋初值时，这个张量中的元素将会显示为那部分计算机内丛中已经存在的值，一般是一些随机的数据，是之前该内存地址上的遗留数据）\n",
        "\n",
        "An alternative is to explicitly set things to be random（另一种做法是明确将内容设计为**随机值**）:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eQ31svwxnmq",
        "outputId": "f16604e3-33d8-4f8d-9c5a-b0cba85cb856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.rand(5, 3)#生成一个形状为[5,3](5行3列)的张量x，每个元素都是随机生成的浮点数，在[0,1)之间均匀分布\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3279, 0.6505, 0.9000],\n",
            "        [0.2546, 0.1983, 0.1175],\n",
            "        [0.5807, 0.1303, 0.5864],\n",
            "        [0.4850, 0.8029, 0.8529],\n",
            "        [0.2348, 0.9817, 0.7001]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3HbYvlUxnmt"
      },
      "source": [
        "Construct a matrix filled zeros and of dtype long（构建一个填充了零且数据类型为长整型的矩阵）:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE59Jus1xnmu",
        "outputId": "7d8f062b-32f1-415e-a506-5cdf79d0a026",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)#5行3列元素全为0的矩阵\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-MIpgIJxnmx"
      },
      "source": [
        "Let us take a list of three numbers in python（在python中取一个包含3个数字的列表）:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qJSZM2Uxnmy"
      },
      "source": [
        "a = [1.0, 2.0, 1.0]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY0NJdpFxnm1"
      },
      "source": [
        "we can access the first element of the list using the index 0（我们可以使用索引0来访问列表的第一个元素）:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNCBoQNPxnm2",
        "outputId": "c14292ba-780f-43fa-900b-04b7ae5765ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a[0]#访问第一个元素"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq2XMYJHxnm4",
        "outputId": "2bda7003-d955-401a-e276-1ba9db7dc1c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a[2] = 3.0#修改第3个元素并输出\n",
        "a"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 2.0, 3.0]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NsruzDGxnm7"
      },
      "source": [
        "We can create a PyTorch tensor（创建PyTorch张量）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCKbW_-qxnm8",
        "outputId": "17e89fcf-ffa0-4d8a-82ca-2c0eee60cdc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "a = torch.ones(3)#创建一个包含3个元素的切全是1的1D张量\n",
        "a"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b=torch.tensor(1)#创建一个值为1的0D张量也就是标量数字1\n",
        "b"
      ],
      "metadata": {
        "id": "_uSsdfH8HD7A",
        "outputId": "1523f590-04ad-4cde-8f7b-3d3cd65bd0f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9-D-648xnm_"
      },
      "source": [
        "The first entry isn't a 1, it is a tensor with one element in it（第一个条目不是1，而是一个包含了一个元素的张量）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZbU3QAyxnnA",
        "outputId": "7b58a106-450b-4e1d-fe51-46366074c587",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a[0]#是一个包含了一个元素1的张量"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbARxFEDxnnC"
      },
      "source": [
        "but you can easily convert it to a float（但是可以很轻松的将其转换为浮点数）:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFoVVplYxnnD",
        "outputId": "66df0b80-bf89-46f6-84d7-b456465c60e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "float(a[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRh9xUE51FpC",
        "outputId": "89fc6745-939e-4398-c520-d58e4c07c7fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a[0].detach().numpy()#提取张量a的第一个元素并将其转换为一个不跟踪梯度的Numpy数组"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(1., dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2RHmhlMxnnF",
        "outputId": "b2e27dd8-31f2-4a9a-b30f-538c3a8db2a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a[1] = 2.0#更改张量中第二个元素的值\n",
        "a"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl-vnqT2xnnH"
      },
      "source": [
        "We can construct a tensor directly from data, by passing a Python list to the constructor（我们可以直接通过向构造函数传递一个Python列表来从数据中构建一个张量）:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp0lEVd0xnnI",
        "outputId": "a9e45fd4-4428-49fb-8965-f0d03e6fb12f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "points = torch.tensor([5.5, 3, 6, 10])#直接构建一个1D张量\n",
        "print(points)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 5.5000,  3.0000,  6.0000, 10.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOV1YuC7xnnK"
      },
      "source": [
        "This has the same result as the code below（下面的代码会有相同的结果）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EXlVZHfxnnL",
        "outputId": "de61a894-1240-4881-93be-5ea35c55e191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "points = torch.zeros(4) # <1>创建一个全为0，包含4个元素的1D张量\n",
        "#为每个元素赋值\n",
        "points[0] = 5.5 # <2>\n",
        "points[1] = 3.0\n",
        "points[2] = 6.0\n",
        "points[3] = 10.0\n",
        "print(points)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 5.5000,  3.0000,  6.0000, 10.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cVj548QxnnM"
      },
      "source": [
        "or create a tensor based on an existing tensor. These methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by user\n",
        "\n",
        "或者基于一个已有的张量创建一个新的张量。这些方法会重新使用输入张量的属性，例如数据类型（dtype），除非用户提供了新的值。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1NphnstxnnN",
        "outputId": "860c4d59-af21-453d-8777-387e58fc2fe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "#new_ones()基于现有的张量创建一个新的张量，该张量的形状由参数决定，为5行3列\n",
        "#新张量的所有元素都是1\n",
        "#制定了新张量的数据类型为双精度浮点数:dtype=torch.double\n",
        "#这里使用x的new_ones()方法一位置新张量将继承x的一些属性，但'dtype'属性被显式覆盖了\n",
        "print(x)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "#利用.randn_like()方法创建一个新的张量，其形状与现有张量x相同，但是元素是从标准正态分布（均值为0，方差为1）中随机抽取的\n",
        "#将数据类型显式的指定为了单精度浮点数，dtype参数确保了新张量会覆盖掉原来的双精度属性\n",
        "print(x)                                      # result has the same size\n",
        "#结果具有相同的形状"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[ 1.4787, -0.3571, -0.1458],\n",
            "        [-1.2915,  0.0990, -1.2732],\n",
            "        [ 0.2190,  0.0528,  0.5199],\n",
            "        [-0.8989,  0.9888, -0.3350],\n",
            "        [ 1.1554,  0.9738,  0.1063]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjpdQILPxnnO",
        "outputId": "8ea10368-cac4-457e-f7e6-06473560ca77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x.size())#重新输出张量的形状"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxnlG_CMxnnQ"
      },
      "source": [
        "Python lists or tuples of numbers are collections of Python objects that are individually allocated in memory. PyTorch tensors or NumPy arrays on the other hand are views over (typically) contiguous memory blocks containing  C numeric types unboxed rather than Python objects. For instance, float32 datatypes would each consist of 32-bit (4 byte) IEEE floating point values. This means that a 1D tensor of 1,000,000 float numbers will require exactly 4,000,000 contiguous bytes to be stored, plus a small overhead for the meta data (e.g. dimensions, numeric type)\n",
        "\n",
        "Python列表或元组中的数字是单独分配在内存中的Python对象集合。另一方面，PyTorch张量或NumPy数组是（通常是）连续内存块的视图，这些内存块包含未封装的C数值类型而不是Python对象。例如，float32数据类型将包含32位（4字节）的IEEE浮点数值。这意味着一个包含1,000,000个浮点数的1D张量将确切需要4,000,000字节的连续字节来存储，加上一小部分元数据（例如，维度、数值类型）的开销。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5apoNXwtxnnQ"
      },
      "source": [
        "What if we want to refer to 2D points? We can create a 2D tensor（如果我们想要引用2D的点，我们可以创建一个2D张量）:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGRZghDfxnnR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71389076-8dda-4bfa-e106-c4006655eb82"
      },
      "source": [
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])#创建一个2D张量\n",
        "points"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 1.],\n",
              "        [5., 3.],\n",
              "        [2., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZk2XbklxnnT"
      },
      "source": [
        "and you can check the shape of a tensor（可以确定张量的形状）:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GtP4LElxnnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc46028d-e2ac-4f52-c37a-48459ee92a32"
      },
      "source": [
        "points.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc_YfvA3xnnX"
      },
      "source": [
        "You can also use zeros or ones to initialise the tensor, giving it a specific shape\n",
        "\n",
        "您也可以使用zeros或ones函数来初始化张量，并给它指定一个特定的形状。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVow0LVQxnnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c26b11e-6fb7-4512-b259-85a7245ce531"
      },
      "source": [
        "points = torch.zeros(3, 2)\n",
        "points"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgxVb5cGLVP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30d22fb-efbd-4a6a-f475-a8b272bfe990"
      },
      "source": [
        "points = torch.ones(3,2)\n",
        "points"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcHvm_SKLb38"
      },
      "source": [
        "By default, tensors are created using datatype torch.float32 (32-bit floating point numbers). However, different datatypes for the elements can be specified with the dtype argument, or there are also methods that create tensors with a specific datatype.\n",
        "\n",
        "默认情况下，张量是使用数据类型torch.float32（32位浮点数）创建的。然而，可以通过dtype参数指定元素的不同数据类型，或者也可以使用创建具有特定数据类型张量的方法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKqgeOxFQ3Q1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a23433-095c-4178-b529-bd92af156ebf"
      },
      "source": [
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], dtype=torch.float32)\n",
        "#创建一个2D张量，并制定张量的数据类型为32位浮点数\n",
        "print(points)\n",
        "print(points.dtype)#输出张量的数据类型"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4., 1.],\n",
            "        [5., 3.],\n",
            "        [2., 1.]])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cOioU7Exnna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a60b44d8-dfc7-40f3-c7e0-7ce2b9c5d8f3"
      },
      "source": [
        "points = torch.FloatTensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
        "#与上一个单元格的代码相同，同样也是创建一个2D张量，FloatTensor预设了张量的数据类型为32位浮点数，所以不需要显示指定'dtype'\n",
        "print(points)\n",
        "print(points.dtype)#输出张量的数据类型"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4., 1.],\n",
            "        [5., 3.],\n",
            "        [2., 1.]])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgbDsiuGxnnc"
      },
      "source": [
        "If we wanted the $y$ coordinate of the 0th point（如果想要第0个点的$y$坐标）:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G93PmXk5xnnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ee1689e-96c5-4d76-f3d8-c944eee92136"
      },
      "source": [
        "points[0, 1]#原本第0个点的坐标为(4.0,1.0)这样直接索引到y坐标，所以只输出tensor(1.)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL9NIUbtxnne"
      },
      "source": [
        "or just get the full 2D coordinates of the 0th point（反正只是获取第0个点的完整2D坐标）:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Wtv--Cxnnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af83aee6-120f-410b-86b9-bf18a8396e73"
      },
      "source": [
        "points[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yBPzCh_xnnh"
      },
      "source": [
        "***Views on storage***\n",
        " Values in Tensors are allocated in contiguous chunks of memory, managed by `torch.Storage` instances. A storage is a one-dimensional array of numerical data, i.e. a contiguous block of memory containing numbers of a given type, such as `float`, 32-bits representing a floating point number, or `int64`, 64-bits representing an integer. A PyTorch  `Tensor` is a view over such a  `Storage` that is capable of indexing into that storage using an offset and and per-dimension strides.\n",
        "\n",
        " 对存储的视图：张量中的值是由'torch.Storage'实例管理的，分配在连续的内存块中。存储(Storage)是一种一维的数值数据数组，即一个包含给定类型数值的连续内存块，如float，32位表示一个浮点数，或int64，64位表示一个整数。一个PyTorch张量是一个对应这样存储的视图，它能够使用一个偏移量和每个维度上的步长来索引进这个存储。\n",
        "\n",
        "\n",
        "\n",
        " Multiple tensors can index the same storage, even if they index into the data differently. When we requested  `points[0]` above, what we got back is another tensor that indexes the same storage as the  tensor, just not all of it and points with different dimensionality (1D vs 2D).  The underlying memory is allocated only once, however, so creating alternate tensor-views on the data can be done quickly, no matter the size of the data managed by the `Storage` instance.\n",
        "\n",
        " 即使它们以不同的方式索引进数据，多个张量也可以索引同一个存储。当我们上面请求points[0]时，我们得到的是另一个索引了同一存储的张量，只是没有全部索引，它指向具有不同维度的数据（1D对比2D）。然而，底层内存只分配了一次，因此在存储实例管理的数据上创建交替的张量视图可以很快完成，无论数据的大小如何。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "所以利用point[0]提取出来的不是原本的张量，虽然仍指向原始存储，但是是一个新的张量，其中包含了原始张量的一部分（也就是第一个维度），意味着原始数据不会被复制，而是通过新的视图（多维张量）来表示"
      ],
      "metadata": {
        "id": "vcG9PklyKdBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "多个张量可以索引同一个存储，例如一个存储的子集的视图sub_tensor的存储sub_tensor.storage()将显示它的全集（也就是原始数据的存储）"
      ],
      "metadata": {
        "id": "2HhEqDaoM4yu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "所谓的偏移量(offset)和步长(stride)就是在取数据的时候从哪个位置开始取，并且怎么取，可以根据设置的步长跳着取）"
      ],
      "metadata": {
        "id": "gc9-cUqrKuJ-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQznXczcxnnh"
      },
      "source": [
        "**Indexing into storage（索引进存储）** Let’s see how indexing into the storage works in practice with our 2D points. The storage for a given tensor is accessible using the `.storage` property（让我们通过实践来了解如何对我们的2D点进行存储索引。可以使用.storage属性来访问给定张量的存储）:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnAwQsqAxnni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f87941f-8199-4263-b19f-7e144ccd5280"
      },
      "source": [
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
        "#这里的存储是一个torch.FloatStorage，大小为6，包含了张量所有元素的值\n",
        "#输出将会按照在内存中的存储顺序排量，表明虽然'points'是一个2D张量，但是其底层数据在物理内存中是连续存储\n",
        "#说明在底层存储中的存储方式是连续的一维数组\n",
        "points.storage()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-8575ff47c9e0>:2: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  points.storage()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 4.0\n",
              " 1.0\n",
              " 5.0\n",
              " 3.0\n",
              " 2.0\n",
              " 1.0\n",
              "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZfNmQM-xnnk"
      },
      "source": [
        "Even though the tensor reports itself as having 3 rows and 2 columns, the storage under the hood is a contiguous array of size 6. In this sense, the tensor just knows how to translate a pair of indices into a location in the storage. We can also index into a storage manually, for instance:\n",
        "\n",
        "尽管张量自报为有3行2列，但底层的存储实际上是一个大小为6的连续数组。从这个意义上讲，张量只是知道如何将一对索引转换为存储中的一个位置（因为实际上在内存中可能是连续存储的，并不是存在真正的索引位置）。我们也可以手动对存储进行索引，例如："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej234D9Txnnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4430dd3-326e-4adf-a22a-a0706db8f478"
      },
      "source": [
        "points_storage = points.storage()\n",
        "print(points_storage[0])#输出第0个索引对应的元素\n",
        "print(points.storage()[1])#输出第一个索引对应的元素\n",
        "#输出的都是存储在内存上的值，而不是张量了"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS9sT6kjxnnl"
      },
      "source": [
        "If you have a one element tensor, use .item() to get the value as a Python number\n",
        "\n",
        "如果你有一个只包含一个元素的张量，使用 .item() 来获取作为Python数值的值。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_SB7up0xnnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b0f553-f7cc-4ef6-96e1-579261951535"
      },
      "source": [
        "print(points[0,1].item())#相当于将张量中对应位置的元素转换为Python的浮点数"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypnBQVYcxnno"
      },
      "source": [
        "We can’t index a storage of a 2D tensor using two indices. The layout of a storage is always one-dimensional, irrespective of the dimensionality of any and all tensors that might refer to it.\n",
        "\n",
        "我们不能使用两个索引来索引一个2D张量的存储。存储的布局始终是一维的，不论引用它的任何张量的维度如何。\n",
        "\n",
        "Changing the value of a storage leads to changing the content of its referring tensor（更改存储的值将导致引用它的张量的内容发生变化）:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsWEyL_3xnnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe02d071-31ef-4e0c-9fc1-848b4b15b448"
      },
      "source": [
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
        "points_storage = points.storage()\n",
        "points_storage[0] = 2.0#更改了存储在第一个位置上的数据的值\n",
        "points#导致相应的张量也发生了变化\n",
        "#说明可以直接修改存储来改变引用它的张量的内容，说明了张量和其存储之间的紧密关联"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 1.],\n",
              "        [5., 3.],\n",
              "        [2., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLsg-upZxnnq"
      },
      "source": [
        "In order to index into a storage, tensors rely on a few pieces of information, which, together with their storage, unequivocally define them: size, storage offset and stride.  The size (or shape, in NumPy parlance) is a tuple indicating how many elements across each dimension the tensor represents. The storage offset is the index in the storage corresponding to the first element in the tensor. Stride is the number of elements in the storage that need to be skipped over to obtain the next element along each dimension.\n",
        "\n",
        "为了对存储进行索引，张量依赖于几个信息，这些信息连同它们的存储一起，明确地定义了它们：大小（size）、存储偏移量（storage offset）和步长（stride）。大小（或在NumPy术语中称为形状shape）是一个元组，指示张量在每个维度上表示的元素数量。存储偏移量是存储中对应于张量中第一个元素的索引。步长是为了获得每个维度上的下一个元素需要在存储中跳过的元素数量。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "大小（Size/Shape）：告诉我们张量在每个维度上有多少个元素，例如，一个3x2的张量的大小是(3, 2)。\n",
        "\n",
        "存储偏移量（Storage Offset）：指明在底层存储中，张量的第一个元素相对于存储开始位置的偏移。这允许张量视图共享同一个存储，而表示不同的数据切片。\n",
        "\n",
        "步长（Stride）：一个元组，表示在每个维度上，从一个元素移动到下一个元素需要跳过的存储中的元素数量。步长决定了张量的布局（如是连续的、是行优先还是列优先等）以及如何快速地计算多维索引在一维存储中的位置。"
      ],
      "metadata": {
        "id": "ScfCdrP6X329"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9H5tEVkxnnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f152ac37-c422-4065-b294-cd834bf1e267"
      },
      "source": [
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
        "second_point = points[1]#取张量中的第二个点赋给变量second_point\n",
        "print(second_point.storage_offset())#打印second_point的存储偏移量\n",
        "#存储偏移量是指'second_point'在'points'的底层存储中第一个元素的位置\n",
        "#因为在底层是按照数组的连续存储，所以'second_point'的第一个元素实际上是存储的第三个元素（索引为2）开始选的，所以偏移量为2（对应的元素索引是2（0->2）)\n",
        "\n",
        "second_point.size(), second_point.shape\n",
        "#.size()和.shape都是查询'second_point的维度的恶，这将返回其在每个维度上的元素数量\n",
        "#因为是1D张量，所以Size类中只包含了一个元素，但这个维度包含了两个元素，所以是2"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2]), torch.Size([2]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS2mXI67xnns"
      },
      "source": [
        "The resulting tensor has offset 2 in the storage (since we need to skip the first point, which has two items) and the size is an instance of the `Size` class containing one element, since the tensor is one-dimensional. Important note: this is the same information as contained in the `shape` property of tensor objects:\n",
        "\n",
        "生成的张量在存储中的偏移量为2（因为我们需要跳过第一个点，它包含两个元素），并且大小（size）是一个 Size 类的实例，其中包含一个元素，因为张量是一维的。重要说明：这与张量对象的 shape 属性中包含的信息相同："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTUCNbgtxnnt"
      },
      "source": [
        "Last, stride is a tuple indicating the number of elements in the storage that have to be skipped when the index is increased by 1 in each dimension. For instance, our `points`  tensor has a stride of : (2, 1)\n",
        "\n",
        "最后，步长（stride）是一个元组，指示在每个维度上，当索引增加1时需要跳过多少个存储中的元素。例如，我们的 points 张量具有以下步长：(2, 1)。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这意味着在第一个维度上（行），当索引增加1时，需要跳过2个元素；在第二个维度上（列），当索引增加1时，需要跳过1个元素。步长的定义允许张量视图可以有效地定位存储中的元素，即使底层存储是连续的一维排列。"
      ],
      "metadata": {
        "id": "Fv5qlDODa6zu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ihnx4YBxnnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277ec204-225b-4b74-a00d-5cc3ae706694"
      },
      "source": [
        "points.stride()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里步长为(2,1)的原因是在第一个维度上，从第一个点（第一行）移动到下一个点（第二行）实际是要跳过两个元素，因为在内部存储中，x坐标和y坐标被存储在连续的位置，所以需要跳过一个x坐标和一个y坐标，所以第一个维度步长为2。\n",
        "\n",
        "而在第二个维度，也就是一个点的内部，x和y坐标本身是连续的，所以在内部存储中没有额外的元素需要跳过）"
      ],
      "metadata": {
        "id": "RnREWeGGb9Vd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5AV3s8Axnnv"
      },
      "source": [
        "This indirection between a tensor and its storage leads to some operations, like transposing a tensor or extracting a sub-tensor, to be inexpensive, as they do not lead to memory reallocations; instead they consist in allocating a new tensor object with a different value for size, storage offset or stride.\n",
        "\n",
        "张量与其存储之间的这种间接关系导致一些操作（例如转置张量或提取子张量）具有低成本，因为它们不会导致内存重新分配；相反，它们仅涉及分配一个具有不同大小、存储偏移或步长值的新张量对象。（这意味着在执行这些操作时，不会实际复制或移动数据，而只是创建一个新的张量对象，该对象引用相同的存储，但具有不同的视图。这提高了操作的效率，并且在处理大型数据集时尤为重要，因为它避免了不必要的内存开销和数据复制。）\n",
        "\n",
        "Let’s try with transposing now. Let’s take our  tensor, that has individual points in the points rows and x and y coordinates in the columns, and turn it around so that individual points are along the columns. We take this opportunity to introduce the  function, a short-hand alternative t for 2-dimensional tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLmwrN-0xnnv"
      },
      "source": [
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
        "points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO-A4W0Kxnnx"
      },
      "source": [
        "points_t = points.t()\n",
        "points_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSZIf7oTxnny"
      },
      "source": [
        "We can easily verify that the two tensors share the same storage:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD0NzKWfxnnz"
      },
      "source": [
        "id(points.storage()) == id(points_t.storage())\n",
        "points.storage()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE5vh50Nxnn0"
      },
      "source": [
        "and that they differ only in the shape and stride\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaW9Fvy1xnn1"
      },
      "source": [
        "points.stride()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt3L7h4Nxnn2"
      },
      "source": [
        "points_t.stride()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77h284bwxnn4"
      },
      "source": [
        "Transposing in PyTorch is not limited to matrices. We can transpose a multidimensional array by specifying the two dimensions along which transposing (i.e. flipping shape and stride) should occur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGhi_PYcxnn5"
      },
      "source": [
        "some_t = torch.ones(3, 4, 5)\n",
        "transpose_t = some_t.transpose(0, 2)\n",
        "some_t.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YelLEqtzxnn7"
      },
      "source": [
        "transpose_t.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p4kxKI1xnn8"
      },
      "source": [
        "some_t.stride()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRus_QGkxnn-"
      },
      "source": [
        "transpose_t.stride()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN6jYO6bxnoE"
      },
      "source": [
        "points.is_contiguous()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyx6dUKKxnoF"
      },
      "source": [
        "points_t.is_contiguous()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av3xEzW1xnoH"
      },
      "source": [
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
        "points_t = points.t()\n",
        "points_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfbWAIZKxnoI"
      },
      "source": [
        "points_t.storage()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0ZBtfIhxnoK"
      },
      "source": [
        "points_t.stride()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF0DEt_nqlYY"
      },
      "source": [
        "The contiguous() method returns a tensor which has had memory reallocated so that the data elements are contiguous in memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnfiUZnMxnoN"
      },
      "source": [
        "points_t_cont = points_t.contiguous()\n",
        "points_t_cont"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbWx-l92xnoO"
      },
      "source": [
        "points_t_cont.stride()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6WFYUPDxnoQ"
      },
      "source": [
        "points_t_cont.storage()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RDto5UcrZkW"
      },
      "source": [
        "Tensors of different datatypes can be allocated by specifying the `dtype` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evoMGCtaxnoS"
      },
      "source": [
        "double_points = torch.ones(10, 2, dtype=torch.double)\n",
        "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJCnDOIXxnoT"
      },
      "source": [
        "print(double_points.dtype)\n",
        "print(short_points.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AStk5MKWr4OY"
      },
      "source": [
        "Alternatively, methods such as `double()` can be used to convert the datatype of a current tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sIPa7sSxnoV"
      },
      "source": [
        "double_points = torch.zeros(5, 2).double()\n",
        "short_points = torch.ones(5, 2).short()\n",
        "print(double_points)\n",
        "print(short_points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQUjGTissLll"
      },
      "source": [
        "The `to()` method can also be used to convert tensors to a particular torch datatype."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cszxvax-xnoX"
      },
      "source": [
        "double_points = torch.zeros(5, 2).to(torch.double)\n",
        "short_points = torch.ones(5, 2).to(dtype=torch.short)\n",
        "print(double_points)\n",
        "print(short_points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ4eN3Qqs135"
      },
      "source": [
        "And finally the method `type()` can also be used to convert tensors to a particular type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USWZzSKTxnoY"
      },
      "source": [
        "points = torch.randn(5, 2)\n",
        "print(points)\n",
        "short_points = points.type(torch.short)\n",
        "print(short_points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjhjIMUGxnoa"
      },
      "source": [
        "# reset points back to original value\n",
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3_jV140xnob"
      },
      "source": [
        "***Indexing Tensors***\n",
        "What if we need to obtain a tensor containing all points but the first? That’s easy using range indexing notation, the same that applies to standard Python lists, which we quickly recall. (Add print statements to the other entries if you are unsure what they will produce as output.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G93Yu9OJxnob"
      },
      "source": [
        "some_list = list(range(6))\n",
        "print(some_list)\n",
        "some_list[:]            # <1>\n",
        "some_list[1:4]          # <2>\n",
        "some_list[1:]           # <3>\n",
        "some_list[:4]           # <4>\n",
        "some_list[:-1]          # <5>\n",
        "print(some_list[1:4:2]) # <6>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEqs-Z-9xnoc"
      },
      "source": [
        "1. all elements in the list\n",
        "2. from element 1 inclusive to element 4 exclusive\n",
        "3. from element 1 inclusive to the end of the list\n",
        "4. from the start of the list to element 4 exclusive\n",
        "5. from the start of the list to one before the last element\n",
        "6. from element 1 inclusive to element 4 exclusive in steps of 2\n",
        "\n",
        "To achieve our goal we can use the same notation for PyTorch tensors, with the added benefit that, just like in NumPy and in other Python scientific libraries, we can use range indexing for each of the dimensions of the tensor:\n",
        "\n",
        "(Again add print statements if you are uncertain what values are produced by any of these statements.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ1OTMx3xnod"
      },
      "source": [
        "print(points)\n",
        "points[1:]          # <1>\n",
        "points[1:, :]       # <2>\n",
        "points[1:, 0]       # <3>\n",
        "print(points[None]) # <4>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAsHejolxnoe"
      },
      "source": [
        "1. All rows after first, implicitly all columns\n",
        "2. All rows after first, all columns\n",
        "3. All rows after first, first column\n",
        "4. Add dimension of size one, just like unsqueeze (note the extra square brackets printed compared to just points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-b_u-Jpxnoe"
      },
      "source": [
        "***Named Tensors***\n",
        "The dimensions (or axes) of our Tensors usually index something like pixel locations or color channels. This means that when we want to index into our Tensor, we need to remember the ordering of the dimensions and write our indexing accordingly. As data is transformed through multiple tensors, keeping track of which dimension contains what data can be error-prone.\n",
        "To make things concrete, imagine that we have a 3D Tensor like `img_t` (we will use dummy data for simplicity here) and want to convert it to grayscale. We looked up typical weights for the colors to derive a single brightness value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuj59ECQxnoh"
      },
      "source": [
        "img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]\n",
        "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJa3p4lzxnoj"
      },
      "source": [
        "We also often want our code to generalize - for example from grayscale images represented as 2D Tensors with height and width dimensions to color images adding a third channel dimension (as in RGB) or from a single image to a batch of images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hb7EqYQxnok"
      },
      "source": [
        "batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCut_4NFxnom"
      },
      "source": [
        "So sometimes the RGB channels are in dimension 0 and sometimes in dimension 1. But we can generalize by counting from the end: They are always in dimension -3, the third from the end. The lazy, unweighted mean would thus be written as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilAe0YwExnom"
      },
      "source": [
        "img_gray_naive = img_t.mean(-3)\n",
        "batch_gray_naive = batch_t.mean(-3)\n",
        "\n",
        "img_gray_naive.shape, batch_gray_naive.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFJOw4iFxnoo"
      },
      "source": [
        "But now we have the weight, too. PyTorch will allow us to multiply things that are of same shape, but also of shapes where one operand is of size one in a given dimension. It also appends leading dimensions of size one automatically. This is a feature called *broadcasting*. We see that our `batch_t` of shape (2, 3, 5, 5) gets multiplied with the `unsqueezed_weights` of shape (3, 1, 1) to a tensor of shape (2, 3, 5, 5), from which we can then sum the third dimension from the end (the 3 channels).\n",
        "\n",
        "Make sure you understand how the `unsqueeze()` method is working from the printed outputs (count the square brackets on the output!), and then also how the broadcasting is working when doing multiplications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e10LpIAIxnop"
      },
      "source": [
        "print(f\"Shape of weights: {weights.shape}\")\n",
        "print(f\"Value: {weights} \\n\")\n",
        "\n",
        "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze(-1)\n",
        "print(f\"Shape of unsqueezed weights: {unsqueezed_weights.shape}\")\n",
        "print(f\"Value: {unsqueezed_weights}\\n\")\n",
        "\n",
        "img_weights = (img_t * unsqueezed_weights)\n",
        "batch_weights = (batch_t * unsqueezed_weights)\n",
        "img_gray_weighted = img_weights.sum(-3)\n",
        "batch_gray_weighted = batch_weights.sum(-3)\n",
        "\n",
        "print(f\"Shape of batch_gray_weighted: {batch_gray_weighted.shape}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV6f4JN1xnoq"
      },
      "source": [
        "Because this gets messy quickly (and for efficiency), there even is a PyTorch function einsum (adapted from NumPy) that specifies an indexing mini-language  giving index names to 28 dimensions for sums of such products. As often in Python, broadcasting — a form of summarizing unnamed things — is done using three dots `...`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzMJKaBmxnor"
      },
      "source": [
        "img_gray_weighted_fancy   = torch.einsum('...chw,c->...hw', img_t, weights)\n",
        "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\n",
        "\n",
        "batch_gray_weighted_fancy.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaDYvZZjxnou"
      },
      "source": [
        "PyTorch 1.3 added  as an experimental feature. Tensor factory functions such as `tensor`  or `rand` take a `names` argument. The names should be a sequence of strings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3tgMq_dxnou"
      },
      "source": [
        "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
        "\n",
        "weights_named\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoJQmR7Jxnow"
      },
      "source": [
        "When we already have a tensor and want to add names (but not change existing ones), we can call the `refine_names` method  on it. Similar to indexing, the ellipsis `...` allows you to leave out refine_names … any number of dimensions. With the  `rename` sibling method you can also overwrite or drop (by passing in `None`) existing names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kunAYEsnxnox"
      },
      "source": [
        "img_named =  img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
        "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
        "\n",
        "print(\"img named:\", img_named.shape, img_named.names)\n",
        "print(\"batch named:\", batch_named.shape, batch_named.names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYQhphHyxnoy"
      },
      "source": [
        "For operations with two inputs, in addition to the usual dimension checks, i.e. that sizes are either the same or one is 1 and can be broadcast to the other, PyTorch will now check the names for us. So far, it does not automatically align dimensions, so we need to do this explicitly. The method  `align_as` returns a tensor with missing dimensions added and existing ones permuted to the right order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwQCsnCFxnoy"
      },
      "source": [
        "weights_aligned = weights_named.align_as(img_named)\n",
        "weights_aligned.shape, weights_aligned.names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T10CfSK7xnoz"
      },
      "source": [
        "Functions accepting dimension arguments, like `sum`, also take named dimensions. A nice feature for robustness is that if you try to combine dimensions with different names, you get an error.  Named tensors have the potential of eliminating many sources of alignment errors which are a frequent source of debugging problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-xwtYZuxnoz"
      },
      "source": [
        "gray_named = (img_named * weights_aligned).sum('channels')\n",
        "\n",
        "gray_named.shape, gray_named.names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25l5sirYx-zN"
      },
      "source": [
        "The code below should create an error..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUrGFk3txno1"
      },
      "source": [
        "gray_named = (img_named[..., :3] * weights_named).sum('channels')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsY17nfNxno3"
      },
      "source": [
        "***Tensor Element Types***\n",
        "Python numeric types can be sub-optimal for several reasons:\n",
        "* Numbers in Python are full-fledged objects. while a floating point number might only take, for instance, 32 bits to be represented on a computer, Python will convert them in a full-fledged Python object with reference counting, etc.. This operation, called boxing, is not a problem if we need to store a small number of them, but allocating millions of such numbers gets very inefficient;\n",
        "* Lists in Python are meant for sequential collections of objects. there are no operations defined for, say, efficiently taking the dot product of two vectors, or summing vectors together; also, Python lists have no way of optimizing the layout of their content in memory, as they are indexable collections of pointers to Python objects (of any kind, not just numbers); last, Python lists are one-dimensional, and while one can create lists of lists, this is again very inefficient;\n",
        "* The Python interpreter is slow compared to optimized, compiled code. Performing mathematical operations on large collections of numerical data can be much faster using optimized code written in a compiled, low-level language like C.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRXiM_n8xno4"
      },
      "source": [
        "For these reasons, data science libraries rely on NumPy, or introduce dedicated data structures like PyTorch tensors, that provide efficient low-level implementations of numerical data structures and related operations on them, wrapped in a convenient high-level API. To enable this, the objects within a tensor must be all numbers of the same type and PyTorch must keep track of this numeric type.\n",
        "\n",
        "The `dtype` argument to tensor constructors (that is, functions like `tensor`, `zeros`, `ones`) specifies the numerical data (d) type that will be contained in the tensor. The data type specifies the possible values the tensor can hold (integers vs. floating point numbers) and the number of bytes per value.  The `dtype` argument is deliberately similar to the standard NumPy argument of the same name.\n",
        "\n",
        "Computations happening in neural networks are typically executed in 32-bit floating point precision. Higher precision, like 64-bit, will not buy us improvements in the accuracy of a model and will require more memory and computing time. The 16-bit floating point, half precision data type is not present natively in standard CPUs, but it is offered on modern GPUs. It is possible to switch to half-precision to decrease the footprint of a neural network model if needed, with minor impact on accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGZsoE6ixno5"
      },
      "source": [
        "PyTorch tensors can be converted to NumPy arrays and vice versa very efficiently. By doing so, we can leverage the huge swath of functionality in the wider Python ecosystem that has built up around the NumPy array type. This zero-copy interoperability with NumPy arrays is due to the storage system working with the Python buffer protocol Converting tensors to `numpy` arrays is very straightforward:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEMha9-Hxno5"
      },
      "source": [
        "points = torch.ones(3, 4)\n",
        "points_np = points.numpy()\n",
        "points_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cg-qvoNxno6"
      },
      "source": [
        "which will return a NumPy multidimensional array of the right size, shape and numerical type. Interestingly, the returned array shares the same underlying buffer with the tensor storage. This means that the `numpy` method can be effectively executed at basically no cost, as long as the data  sits in CPU RAM. It also means that modifying the NumPy array will lead to a change in the originating tensor.\n",
        "If the tensor is allocated on the GPU, PyTorch will make a copy of the content of the tensor into a NumPy array allocated on the CPU.\n",
        "Vice-versa, we can obtain a PyTorch tensor from a NumPy array this way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DJDbWH8xno7"
      },
      "source": [
        "points = torch.from_numpy(points_np)\n",
        "points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skkE5HKfxno8"
      },
      "source": [
        "While the default numeric type in PyTorch is 32 bit floating point, for the one for numpy it is 64 bit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymCxDxLhxno8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "a = torch.ones(5)\n",
        "print(a, a.dtype)\n",
        "b = a.numpy()\n",
        "print(b, b.dtype)\n",
        "\n",
        "c = np.ones(5)\n",
        "print(c, c.dtype)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn3ZFASKxno9"
      },
      "source": [
        "Note how the `numpy` array changes value if we change the `tensor`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqGJ69GRxno9"
      },
      "source": [
        "print(a)\n",
        "print(b)\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyc45I7mxnpB"
      },
      "source": [
        "***Serialising tensors***\n",
        "\n",
        "Creating a tensor on the fly is all well and fine, but if the data inside is of any value to us, we will want to save it to a file and load it back at some point. After all, we don’t want to have to retrain a model from scratch every time we start running our program! PyTorch uses `pickle` under the hood to serialize the tensor object, plus dedicated serialization code for the storage. Here’s how we can save our `points` tensor to an `ourpoints.t` file: (note that this won't work as is in `colab` but would be fine if you ran the notebook locally on your machine -- we'll cover colab file issues later)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow1F91yRxnpB"
      },
      "source": [
        "torch.save(points, './drive/../data/p1ch3/ourpoints.t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b99E4BkSYC5T"
      },
      "source": [
        "One way to save and load data from and to colab is to mount a google drive (you will get some space with your account if you created it for colab)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjmqXdoBX30f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFk5xlNcxnpC"
      },
      "source": [
        "As an alternative, we can pass a file descriptor in lieu of the filename"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-4a6L_OYXeo"
      },
      "source": [
        "torch.save(points, '/content/drive/MyDrive/ourpoints.t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHG5EnYqxnpC"
      },
      "source": [
        "with open('/content/drive/MyDrive/ourpoints.t','wb') as f:\n",
        "   torch.save(points, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWpKDg6uxnpD"
      },
      "source": [
        "points = torch.load('/content/drive/MyDrive/ourpoints.t')\n",
        "points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaXNHWhuxnpF"
      },
      "source": [
        "with open('/content/drive/MyDrive/ourpoints.t','rb') as f:\n",
        "   points = torch.load(f)\n",
        "\n",
        "points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ocH-FqoxnpI"
      },
      "source": [
        "While this is a way we can quickly save tensors in case we only want to load them with PyTorch, the file format itself is not interoperable. We can’t read the tensor with software other than PyTorch. Depending on the use case, this may or may not be a limitation, but we should learn how to save tensors interoperably for those times it is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKfiLH5WxnpI"
      },
      "source": [
        "***Serialising to HDF5 with h5py***\n",
        "\n",
        "For those cases when you need to, however, you can use the HDF5 format and library. HDF5 is a portable and widely supported format for representing serialized multidimensional arrays, organized in a nested key-value dictionary. Python supports HDF5 through the  library `h5py`, which accepts and returns data under the form of NumPy arrays.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIonJBmBxnpJ"
      },
      "source": [
        "import h5py\n",
        "\n",
        "f = h5py.File('/content/drive/MyDrive/ourpoints.hdf5', 'w')\n",
        "dset = f.create_dataset('coords', data=points.numpy())\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOBe_T1oxnpJ"
      },
      "source": [
        "Here `coords` is a key into the HDF5 file. We can have other keys, even nested ones. One of the interesting things in HDF5 is that we can index the dataset while on disk and access only the elements we are interested in. Let us suppose we want to load just the last two points in our dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjpHSQYlxnpK"
      },
      "source": [
        "f = h5py.File('/content/drive/MyDrive/ourpoints.hdf5', 'r')\n",
        "dset = f['coords']\n",
        "last_points = dset[-2:]\n",
        "last_points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew8KQl8rxnpL"
      },
      "source": [
        "What happened here is that data has not been loaded when the file was opened or the dataset was required. Rather, data stayed on disk until we requested the second and last rows in the dataset. At that point `h5py`,  has accessed those two columns and returned a NumPy array-like object encapsulating that region in that dataset that behaves like a NumPy array and has the same API.\n",
        "Owing to this fact, we can pass the returned object to the `torch.from_numpy` function to obtain  a tensor directly. Note that in this case the data is copied over to the tensor’s storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_5gVEZHxnpL"
      },
      "source": [
        "last_points = torch.from_numpy(dset[-2:])\n",
        "f.close()\n",
        "last_points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRiuldkaxnpP"
      },
      "source": [
        "***Moving tensors to the GPU***\n",
        " Every Torch tensor can be transferred to (one of) the GPU(s) in order to perform massively parallel, fast computations. All operations that will be performed on the tensor will be carried out using GPU-specific routines that come with PyTorch. In addition to the `dtype`, a PyTorch `Tensor` also has a notion of `device`, which is where on the computer the tensor data is being placed. Here is how we can create a tensor on the GPU by specifying the corresponding argument to the constructor:\n",
        "(Note: if running this in Colab you must have changed 'runtime' to 'GPU' for this to work - in the Edit/Notebook Settings menu item.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqoZM8f4xnpQ"
      },
      "source": [
        "import torch # Doing this again since your Notebook would have been reset if you changed settings.\n",
        "\n",
        "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')\n",
        "points_gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3_8pRs7xnpR"
      },
      "source": [
        "We could instead copy a tensor created on the CPU onto the GPU using the  method `to()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6UFWdcYxnpR"
      },
      "source": [
        "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cpu')\n",
        "points_gpu = points.to(device='cuda')\n",
        "\n",
        "points_gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EOQV9eYxnpT"
      },
      "source": [
        "Doing so returns a new tensor that has the same numerical data, but stored in the RAM of the GPU, rather than in regular system RAM. Now that the data is stored locally on the GPU, we’ll start to see the speedups mentioned earlier when performing mathematical operations on the tensor. In almost all cases, CPU- and GPU-based tensors expose the same user-facing API, making it much easier to write code that is agnostic to where, exactly, the heavy number crunching is running.\n",
        "\n",
        "In case our machine has more than one GPU, we can also decide on which GPU we allocate the tensor by passing a zero-based integer identifying the GPU on the machine, such as\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r50REDPlxnpU"
      },
      "source": [
        "points_gpu = points.to(device='cuda:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQq-KkCGxnpV"
      },
      "source": [
        "points = 2 * points                         # <1>\n",
        "points_gpu = 2 * points.to(device='cuda')   # <2>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR6SjS9ExnpV"
      },
      "source": [
        "1. Multiplication performed on the CPU.\n",
        "2. Multiplication performed on the GPU.\n",
        "\n",
        "Note that the  tensor is not brought back to the CPU once the result has been points_gpu computed. What happened in the line above is that\n",
        "\n",
        "1) the  tensor has been copied to the GPU;\n",
        "2) a new tensor has been allocated on the GPU points and used to store the result of the multiplication;\n",
        "3) a handle to that GPU tensor is returned.\n",
        "\n",
        "Therefore, if we also add a constant to the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FOJWiGixnpW"
      },
      "source": [
        "points_gpu = points_gpu + 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8hV1XA-xnpX"
      },
      "source": [
        "the addition is still performed on the GPU, no information flows to the CPU (except if we print or access the resulting tensor). In order to move the tensor back to the CPU we need to provide a `cpu` argument to the `to` method, such as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Prn7LkxnpX"
      },
      "source": [
        "points_cpu = points_gpu.to(device='cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCq26o3-Ltz5"
      },
      "source": [
        "There are also specific methods to transfer tensors between the CPU and GPU(s)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnuxJC2axnpY"
      },
      "source": [
        "points_gpu = points.cuda()\n",
        "points_gpu = points.cuda(0)\n",
        "points_cpu = points_gpu.cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FjlpBUexnpZ"
      },
      "source": [
        "***The tensor API***\n",
        "\n",
        "Let's get a feel for the tensor operations that PyTorch offers, to give a feel for the API. The vast majority of operations on and between tensors are available under the `torch` module https://pytorch.org/docs/stable/torch.html and can also be called as methods of a tensor object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5-klzrwxnpZ"
      },
      "source": [
        "a = torch.ones(3, 2)\n",
        "a_t = torch.transpose(a, 0, 1)\n",
        "\n",
        "a.shape, a_t.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5FD1r__xnpa"
      },
      "source": [
        "or, for exactly the same result, as a method of the `a` tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rssecS1Kxnpa"
      },
      "source": [
        "a = torch.ones(3, 2)\n",
        "a_t = a.transpose(0, 1)\n",
        "\n",
        "a.shape, a_t.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7TSseWDxnpb"
      },
      "source": [
        "For more details look at the online docs http://pytorch.org/docs They are exhaustive and well organized, with the tensor operations divided into groups:\n",
        "* Creation ops — functions for constructing a tensor, like `ones`  and `from_numpy`\n",
        "* Indexing, slicing, joining, mutating ops — functions for changing the shape, stride or content a tensor, like `transpose`\n",
        "* Math ops — functions for manipulating the content of the tensor through computations\n",
        "    * Pointwise ops — functions for obtaining a new tensor by applying a function to each element independently, like `abs` and  `cos`\n",
        "    * Reduction ops — functions for computing aggregate values by iterating through tensors, like `mean`, `std` and `norm`\n",
        "    * Comparison ops — functions for evaluating numerical predicates over tensors, like `equal` and `max`\n",
        "    * Spectral ops — functions for transforming in and operating in the frequency domain, like `stft` and `hamming_window`\n",
        "    * Other operations — special functions operating on vectors, like `cross`, or matrices, like `trace`\n",
        "    * BLAS and LAPACK operations — functions following the BLAS (Basic Linear Algebra Subprograms) specification for scalar, vector-vector, matrix-vector and matrix-matrix operations\n",
        "* Random sampling — functions for generating values by drawing randomly from probability distributions, like `randn` and `normal`\n",
        "* Serialization — functions for saving and loading tensors, like `load` and `save`\n",
        "* Parallelism — functions for controlling the number of threads for parallel CPU execution, like `set_num_threads`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCDrPfaJxnpd"
      },
      "source": [
        "***Summary***\n",
        "\n",
        "* Neural networks transform floating point representations into other floating point representations, with the starting and ending representations typically being human-interpretable. The intermediate representations are less so.\n",
        "* These floating point representations are stored in Tensors.\n",
        "* Tensors are multidimensional arrays; they are the basic data structure in PyTorch.\n",
        "* PyTorch has a comprehensive standard library for tensor creation, manipulation and mathematical operations.\n",
        "* Tensors can be serialized to disk and loaded back.\n",
        "* All tensor operations in PyTorch can execute on the CPU as well as on the GPU, with no change in the code.\n",
        "* PyTorch uses a trailing underscore to indicate that a function operates in-place on a tensor (e.g. `Tensor.sqrt_`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCSKmTNvXy_z"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}